{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "canada_ped_ctg_ppg_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ps0GWucTalOa",
        "outputId": "f923b00b-70fb-4174-a300-5b8ae85f8add"
      },
      "source": [
        "'''\n",
        "https://ileanacabada.medium.com/price-elasticity-of-demand-using-linear-regression-in-python-part-1-a28c844c1656\n",
        "https://medium.com/geekculture/price-elasticity-of-demand-using-linear-regression-in-python-part-2-8adb654328e7\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhttps://ileanacabada.medium.com/price-elasticity-of-demand-using-linear-regression-in-python-part-1-a28c844c1656\\nhttps://medium.com/geekculture/price-elasticity-of-demand-using-linear-regression-in-python-part-2-8adb654328e7\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "rXB8brjAarLb",
        "outputId": "2e5f04d7-87ff-4ca8-adb5-23a5f1ed45d8"
      },
      "source": [
        "'''\n",
        "level level\n",
        "---------------------\n",
        "q = c + m * p\n",
        "e = (m * p) / q\n",
        "\n",
        "log level\n",
        "---------------------\n",
        "log(q) = c + m * p\n",
        "e = m * p\n",
        "\n",
        "level log\n",
        "---------------------\n",
        "q = c + m * log(x)\n",
        "e = m / q\n",
        "\n",
        "log log\n",
        "---------------------\n",
        "log(q) = c + m * log(p)\n",
        "e = m\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nlevel level\\n---------------------\\nq = c + m * p\\ne = (m * p) / q\\n\\nlog level\\n---------------------\\nlog(q) = c + m * p\\ne = m * p\\n\\nlevel log\\n---------------------\\nq = c + m * log(x)\\ne = m / q\\n\\nlog log\\n---------------------\\nlog(q) = c + m * log(p)\\ne = m\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK-4UnJ6anvF"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from statsmodels.formula.api import ols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpr0liEtbhAf"
      },
      "source": [
        "br1_ctg = [142, 18, 131, 166, 22, 25, 233, 1, 196, 54, 4, 58]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1LD358ciopQ"
      },
      "source": [
        "elasticity_explanation = ['self-inelastic', 'self-unit-elastic', 'self-elastic', 'self-positive-elastic']    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2V-WZUIavnU"
      },
      "source": [
        "def divergent_plot(df, values_column, ylabel, xlabel):\n",
        "\n",
        "    #Divergent plot\n",
        "    df['overall_ped_ranking'] = df[values_column].rank( ascending = True).astype(int)\n",
        "    df.sort_values(values_column, ascending =False, inplace = True)\n",
        "    plt.figure(figsize = (10,50), dpi = 100)\n",
        "    plt.hlines(y = df['overall_ped_ranking'] , xmin = 0, xmax = df[values_column], alpha = 0.5, linewidth = 3)\n",
        "    \n",
        "    #Add elasticity labels\n",
        "    for x, y, tex in zip(df[values_column], df['overall_ped_ranking'] , df[values_column]):\n",
        "        plt.text(x, y, round(tex, 2), horizontalalignment='right' if x < 0 else 'left', \n",
        "                 verticalalignment='center', fontdict={'color':'red' if x < 0 else 'green', 'size':10})\n",
        "        \n",
        "    \n",
        "    # Axis and title\n",
        "    plt.gca().set(ylabel= ylabel, xlabel= xlabel)\n",
        "    plt.yticks(df['overall_ped_ranking'])\n",
        "    plt.title(values_column , fontdict={'size':15})\n",
        "    plt.grid(linestyle='--', alpha=0.5)\n",
        "    plt.show()\n",
        "            \n",
        "    \n",
        "    #Adjust Ranking column and print dataframe\n",
        "    pd.set_option('display.width', 4000)\n",
        "    cols = list(df.columns)\n",
        "    cols = [cols[-1]] + cols[:-1]\n",
        "    df = df[cols]\n",
        "    \n",
        "    df = df.iloc[:,:3]\n",
        "    df.set_index('overall_ped_ranking', inplace=True)\n",
        "    display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6l8Gk0canx2"
      },
      "source": [
        "df_ctg_ppg = pd.read_csv(\"prod_ctg_ppg.csv\")\n",
        "df_ctg_ppg.columns = [c.lower() for c in df_ctg_ppg.columns]\n",
        "df_ctg_ppg = df_ctg_ppg.dropna()\n",
        "df_ctg_ppg.prod_category = df_ctg_ppg['prod_category'].astype(int)\n",
        "df_ctg = df_ctg_ppg[['prod_category', 'category_desc']].drop_duplicates()\n",
        "df_ppg_list = df_ctg_ppg[['ppg_id', 'ppg_desc']].drop_duplicates()\n",
        "df_ctg_ppg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve-YfpRAan1L"
      },
      "source": [
        "df_uch_level_g = pd.read_csv(\"result_uch_level_e_uch_level_g.csv\")\n",
        "df_uch_level_g.columns = [c.lower() for c in df_uch_level_g.columns]\n",
        "df_uch_level_g = df_uch_level_g.dropna()\n",
        "df_uch_level_g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfAE8Zyaan3f"
      },
      "source": [
        "#Format and build a dataframe with x_values for each product within the uch_level_g \n",
        "df = pd.read_csv(\"result_elasticity_data_ctg.csv\")\n",
        "df.columns = [c.lower() for c in df.columns]\n",
        "df['total_sales_units_log'] = np.log(df.total_sales_units)\n",
        "df['avg_price_per_unit_to_consmer_log'] = np.log(df.avg_price_per_unit_to_consmer)\n",
        "orig_df = df.copy()\n",
        "df = df[df.prod_category.isin(br1_ctg)]\n",
        "df = df.sort_values(by=['fscl_wk_end_dt', 'prod_category', 'uch_level_g'])\n",
        "\n",
        "unique_cust_ctg_comb_list = df[['uch_level_g', 'prod_category']].drop_duplicates().values.tolist()\n",
        "\n",
        "df_unique_cust_ctg_comb = pd.DataFrame(df.groupby(['uch_level_g', 'prod_category']).size()).reset_index()\n",
        "df_unique_cust_ctg_comb.columns = [ 'uch_level_g', 'prod_category', 'combination_count']\n",
        "error_list = []\n",
        "\n",
        "ols_results_values = {\n",
        "    \"uch_level_g\": [],\n",
        "    \"prod_category\": [],\n",
        "    \"price_elasticity\": [],\n",
        "    \"price_mean\": [],\n",
        "    \"quantity_mean\": [],\n",
        "    \"intercept\": [],\n",
        "    \"t_score\":[],\n",
        "    \"slope\": [],\n",
        "    \"coefficient_pvalue\" : [],\n",
        "    \"rsquared\" : [],\n",
        "    \"msg\" : []\n",
        "}\n",
        "\n",
        "for uc in unique_cust_ctg_comb_list:\n",
        "    #output_str = \"Record count for the combination \" + uc[0] + \", prod_category \" + str(uc[1]) + \" is \" + df_unique_cust_ctg_comb[(df_unique_cust_ctg_comb.uch_level_g ==  uc[0]) & (df_unique_cust_ctg_comb.prod_category == uc[1])]['combination_count'].astype(str)\n",
        "    print(\"customer \" + uc[0])\n",
        "    print(\"prod_category \" + str(uc[1]))\n",
        "    print(\"Combination count \" + str(df_unique_cust_ctg_comb[(df_unique_cust_ctg_comb.uch_level_g ==  uc[0]) & (df_unique_cust_ctg_comb.prod_category == uc[1])][['combination_count']].values[0][0]))\n",
        "    print(\"******\")\n",
        "    test_df = df[(df.uch_level_g == uc[0]) & (df.prod_category == uc[1])][['fscl_wk_end_dt', 'total_sales_units_log', 'avg_price_per_unit_to_consmer_log']]\n",
        "    test_df.set_index(\"fscl_wk_end_dt\", inplace=True)\n",
        "    try:\n",
        "        model_cust_ctg_elasticity = ols(\"total_sales_units_log ~ avg_price_per_unit_to_consmer_log\", data = test_df).fit()\n",
        "        print(model_cust_ctg_elasticity.summary())\n",
        "        \n",
        "        rsquared = model_cust_ctg_elasticity.rsquared\n",
        "        coefficient_pvalue = model_cust_ctg_elasticity.f_pvalue\n",
        "        intercept, slope = model_cust_ctg_elasticity.params\n",
        "        mean_price = np.mean(test_df.avg_price_per_unit_to_consmer_log)\n",
        "        mean_quantity = np.mean(test_df.total_sales_units_log)\n",
        "        tintercept, t_score = model_cust_ctg_elasticity.tvalues\n",
        "     \n",
        "        #Price elasticity Formula\n",
        "        #price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
        "        price_elasticity = (slope)\n",
        "            \n",
        "        #Append results into dictionary for dataframe\n",
        "        ols_results_values[\"uch_level_g\"].append(uc[0])\n",
        "        ols_results_values[\"prod_category\"].append(uc[1])\n",
        "        ols_results_values[\"price_elasticity\"].append(price_elasticity)\n",
        "        ols_results_values[\"price_mean\"].append(mean_price)\n",
        "        ols_results_values[\"quantity_mean\"].append(mean_quantity)\n",
        "        ols_results_values[\"intercept\"].append(intercept)\n",
        "        ols_results_values['t_score'].append(t_score)\n",
        "        ols_results_values[\"slope\"].append(slope)\n",
        "        ols_results_values[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
        "        ols_results_values['rsquared'].append(rsquared)\n",
        "        if coefficient_pvalue < 0.05:\n",
        "            ols_results_values[\"msg\"].append(\"coefficient_pvalue < 0.05, statistically significant results\")\n",
        "        else:\n",
        "            ols_results_values[\"msg\"].append(\"coefficient_pvalue >= 0.05, statistically insignificant results\")\n",
        "        print(\"Model results printed\")\n",
        "    except:\n",
        "        print(\"Error occurred\")\n",
        "        error_list.append(uc)\n",
        "\n",
        "final_df = pd.DataFrame.from_dict(ols_results_values)\n",
        "df_elasticity = final_df[['uch_level_g', 'prod_category', 'price_elasticity', 't_score', 'coefficient_pvalue', 'slope', 'price_mean', 'quantity_mean', 'intercept', 'rsquared', 'msg']]\n",
        "\n",
        "pe_plot = divergent_plot(df_elasticity, 'price_elasticity', 'overall_ped_ranking', 'price_elasticity')\n",
        "df_elasticity = df_elasticity.sort_values(by=['prod_category', 'price_elasticity'], ascending=[True, True])\n",
        "\n",
        "df_elasticity_l1 = pd.merge(df_elasticity, df_ctg, on = ['prod_category'], how='inner')\n",
        "df_elasticity_l2 = pd.merge(df_elasticity_l1, df_uch_level_g, on = ['uch_level_g'], how='inner')\n",
        "\n",
        "cust_ctg_elasticity_conditions_1 = [\n",
        "    (df_elasticity_l2['price_elasticity'] <= 0) & (df_elasticity_l2['price_elasticity'] > -1),\n",
        "    (df_elasticity_l2['price_elasticity'] == -1.000000000),\n",
        "    (df_elasticity_l2['price_elasticity'] < -1),\n",
        "    (df_elasticity_l2['price_elasticity'] > 0)\n",
        "    ]    \n",
        "\n",
        "df_elasticity_l2['elasticity_explanation'] = np.select(cust_ctg_elasticity_conditions_1, elasticity_explanation)\n",
        "df_elasticity_l2.to_csv(\"canada_cust_ctg_elasticity_details.csv\", index=False)\n",
        "\n",
        "df_ped = pd.DataFrame()\n",
        "for ctg in sorted(list(df_elasticity['prod_category'].drop_duplicates())):\n",
        "    test_df_ped = df_elasticity[(df_elasticity.prod_category == ctg)].reset_index().iloc[:,1:]\n",
        "    test_df_ped['ctg_ped_ranking'] = test_df_ped['price_elasticity'].rank(ascending = True).astype(int)\n",
        "    test_df_ped.sort_values('price_elasticity', ascending =False, inplace = True)\n",
        "    plt.figure(figsize = (20,10), dpi = 100)\n",
        "    plt.hlines(y = test_df_ped['ctg_ped_ranking'] , xmin = 0, xmax = test_df_ped['price_elasticity'], alpha = 0.5, linewidth = 3)\n",
        "    \n",
        "    \n",
        "    #Add elasticity labels\n",
        "    for x, y, tex in zip(test_df_ped['price_elasticity'], test_df_ped['ctg_ped_ranking'] , test_df_ped['price_elasticity']):\n",
        "        plt.text(x, y, round(tex, 2), horizontalalignment='right' if x < 0 else 'left', \n",
        "                 verticalalignment='center', fontdict={'color':'red' if x < 0 else 'green', 'size':15})\n",
        "    \n",
        "    # Axis and title\n",
        "    ylabel, xlabel = 'Ranking Number', 'Price Elasticity'\n",
        "    plt.gca().set(ylabel= ylabel, xlabel= xlabel)\n",
        "    plt.yticks(test_df_ped['ctg_ped_ranking'])\n",
        "    plt.title('price_elasticity' , fontdict={'size':15})\n",
        "    plt.grid(linestyle='--', alpha=0.5)\n",
        "    plt.show()\n",
        "    \n",
        "    #Adjust Ranking column and print dataframe\n",
        "    pd.set_option('display.width', 4000)\n",
        "    #cols = list(test_df_ped.columns)\n",
        "    #cols = [cols[-1]] + cols[:3]\n",
        "    cols = ['uch_level_g', 'prod_category', 'price_elasticity', 'ctg_ped_ranking', 'msg']\n",
        "    test_df_ped = test_df_ped[cols]\n",
        "    \n",
        "    test_df_ped = test_df_ped.iloc[:,:5]\n",
        "    test_df_ped.set_index('ctg_ped_ranking', inplace=True)\n",
        "    display(test_df_ped)\n",
        "    test_df_ped['ctg_ped_ranking'] = test_df_ped.index\n",
        "    df_ped = df_ped.append(test_df_ped)\n",
        "\n",
        "df_ped = df_ped.sort_values(by=['prod_category', 'price_elasticity'], ascending=[True, True])\n",
        "cust_ctg_elasticity_conditions = [\n",
        "    (df_ped['price_elasticity'] <= 0) & (df_ped['price_elasticity'] > -1),\n",
        "    (df_ped['price_elasticity'] == -1.000000000),\n",
        "    (df_ped['price_elasticity'] < -1),\n",
        "    (df_ped['price_elasticity'] > 0)\n",
        "    ]\n",
        "df_ped['elasticity_explanation'] = np.select(cust_ctg_elasticity_conditions, elasticity_explanation)\n",
        "\n",
        "#df_ped.to_csv(\"canada_cust_ctg_elasticity_summary.csv\", index=False)\n",
        "df_ped_l1 = pd.merge(df_ped, df_ctg, on = ['prod_category'], how='inner')\n",
        "df_ped_l2 = pd.merge(df_ped_l1, df_uch_level_g, on = ['uch_level_g'], how='inner')\n",
        "df_ped_l2.to_csv(\"canada_cust_ctg_elasticity_summary.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Iynvq2_V7kX"
      },
      "source": [
        "orig_df_pivot = orig_df.pivot(index = 'fscl_wk_end_dt', columns = ['uch_level_g','prod_category'], values = 'total_sales_units')\n",
        "formatted_column_name_list = []\n",
        "for c in orig_df_pivot.columns:\n",
        "    formatted_column_name_list.append(c[0] + '_ctg' + str(c[1]))\n",
        "orig_df_pivot.columns = formatted_column_name_list\n",
        "orig_df_pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftxdMrgeWsxZ"
      },
      "source": [
        "orig_df_pivot.plot(figsize=(40,20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H3zkiQ4x9EW"
      },
      "source": [
        "file_name_1 = \"result_elasticity_data_ppg_1.csv\"\n",
        "file_name_2 = \"result_elasticity_data_ppg_2.csv\"\n",
        "\n",
        "df1 = pd.read_csv(file_name_1)\n",
        "df2 = pd.read_csv(file_name_2)\n",
        "df_ppg = pd.concat([df1, df2])\n",
        "df_ppg.columns = [c.lower() for c in df_ppg.columns]\n",
        "df_ppg['total_sales_units_log'] = np.log(df_ppg.total_sales_units)\n",
        "df_ppg['avg_price_per_unit_to_consmer_log'] = np.log(df_ppg.avg_price_per_unit_to_consmer)\n",
        "orig_df_ppg = df_ppg.copy()\n",
        "orig_df_ppg.columns = [c.lower() for c in orig_df_ppg.columns]\n",
        "df_ppg = df_ppg[df_ppg.prod_category.isin(br1_ctg)]\n",
        "df_ppg = df_ppg.sort_values(by=['fscl_wk_end_dt', 'prod_category', 'ppg_id', 'uch_level_g'])\n",
        "\n",
        "unique_cust_ctg_ppg_comb_list = df_ppg[['uch_level_g', 'prod_category', 'ppg_id']].drop_duplicates().values.tolist()\n",
        "\n",
        "df_unique_cust_ctg_ppg_comb = pd.DataFrame(df_ppg.groupby(['uch_level_g', 'prod_category', 'ppg_id']).size()).reset_index()\n",
        "df_unique_cust_ctg_ppg_comb.columns = [ 'uch_level_g', 'prod_category', 'ppg_id', 'combination_count']\n",
        "error_list = []\n",
        "\n",
        "ols_results_values_1 = {\n",
        "    \"uch_level_g\": [],\n",
        "    \"prod_category\": [],\n",
        "\t  \"ppg_id\": [],\n",
        "    \"price_elasticity\": [],\n",
        "    \"price_mean\": [],\n",
        "    \"quantity_mean\": [],\n",
        "    \"intercept\": [],\n",
        "    \"t_score\":[],\n",
        "    \"slope\": [],\n",
        "    \"coefficient_pvalue\" : [],\n",
        "    \"rsquared\" : [],\n",
        "    \"msg\" : []\n",
        "}\n",
        "\n",
        "for uc in unique_cust_ctg_ppg_comb_list:\n",
        "    print(\"customer \" + uc[0])\n",
        "    print(\"prod_category \" + str(uc[1]))\n",
        "    print(\"ppg_id \" + str(uc[2]))\n",
        "    val = (df_unique_cust_ctg_ppg_comb[(df_unique_cust_ctg_ppg_comb.uch_level_g ==  uc[0]) & \n",
        "                                      (df_unique_cust_ctg_ppg_comb.prod_category == uc[1]) & \n",
        "                                      (df_unique_cust_ctg_ppg_comb.ppg_id == uc[2])][['combination_count']].values[0][0])\n",
        "    print(\"Combination count \" + str(val))\n",
        "    print(\"******\")\n",
        "    test_df_ppg = df_ppg[(df_ppg.uch_level_g == uc[0]) & (df_ppg.prod_category == uc[1]) & (df_ppg.ppg_id == uc[2])][['fscl_wk_end_dt', 'total_sales_units_log', 'avg_price_per_unit_to_consmer_log']]\n",
        "    test_df_ppg.set_index(\"fscl_wk_end_dt\", inplace=True)\n",
        "    try:\n",
        "        model_cust_ctg_ppg_elasticity = ols(\"total_sales_units_log ~ avg_price_per_unit_to_consmer_log\", data = test_df_ppg).fit()\n",
        "        print(model_cust_ctg_ppg_elasticity.summary())\n",
        "        \n",
        "        rsquared = model_cust_ctg_ppg_elasticity.rsquared\n",
        "        coefficient_pvalue = model_cust_ctg_ppg_elasticity.f_pvalue\n",
        "        intercept, slope = model_cust_ctg_ppg_elasticity.params\n",
        "        mean_price = np.mean(test_df_ppg.avg_price_per_unit_to_consmer_log)\n",
        "        mean_quantity = np.mean(test_df_ppg.total_sales_units_log)\n",
        "        tintercept, t_score = model_cust_ctg_ppg_elasticity.tvalues\n",
        "     \n",
        "        #Price elasticity Formula\n",
        "        #price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
        "        price_elasticity = (slope)\n",
        "            \n",
        "        #Append results into dictionary for dataframe\n",
        "        ols_results_values_1[\"uch_level_g\"].append(uc[0])\n",
        "        ols_results_values_1[\"prod_category\"].append(uc[1])\n",
        "        ols_results_values_1[\"ppg_id\"].append(uc[2])\n",
        "        ols_results_values_1[\"price_elasticity\"].append(price_elasticity)\n",
        "        ols_results_values_1[\"price_mean\"].append(mean_price)\n",
        "        ols_results_values_1[\"quantity_mean\"].append(mean_quantity)\n",
        "        ols_results_values_1[\"intercept\"].append(intercept)\n",
        "        ols_results_values_1['t_score'].append(t_score)\n",
        "        ols_results_values_1[\"slope\"].append(slope)\n",
        "        ols_results_values_1[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
        "        ols_results_values_1['rsquared'].append(rsquared)\n",
        "        if coefficient_pvalue < 0.05:\n",
        "            ols_results_values_1[\"msg\"].append(\"coefficient_pvalue < 0.05, statistically significant results\")\n",
        "        else:\n",
        "            ols_results_values_1[\"msg\"].append(\"coefficient_pvalue >= 0.05, statistically insignificant results\")\n",
        "        print(\"Model results printed\")\n",
        "    except:\n",
        "        print(\"Error occurred\")\n",
        "        error_list.append(uc)\n",
        "\n",
        "final_df_ppg = pd.DataFrame.from_dict(ols_results_values_1)\n",
        "df_elasticity_ppg = final_df_ppg[['uch_level_g', 'prod_category', 'ppg_id', 'price_elasticity', 't_score', 'coefficient_pvalue', 'slope', 'price_mean', 'quantity_mean', 'intercept', 'rsquared', 'msg']]\n",
        "\n",
        "pe_plot_ppg = divergent_plot(df_elasticity_ppg, 'price_elasticity', 'overall_ped_ranking', 'price_elasticity')\n",
        "df_elasticity_ppg = df_elasticity_ppg.sort_values(by=['prod_category', 'ppg_id', 'price_elasticity'], ascending=[True, True, True])\n",
        "\n",
        "df_elasticity_ppg_l1 = pd.merge(df_elasticity_ppg, df_ctg_ppg, on = ['prod_category', 'ppg_id'], how='inner')\n",
        "df_elasticity_ppg_l2 = pd.merge(df_elasticity_ppg_l1, df_uch_level_g, on = ['uch_level_g'], how='inner')\n",
        "cust_ctg_ppg_elasticity_conditions_1 = [\n",
        "    (df_elasticity_ppg_l2['price_elasticity'] <= 0) & (df_elasticity_ppg_l2['price_elasticity'] > -1),\n",
        "    (df_elasticity_ppg_l2['price_elasticity'] == -1.000000000),\n",
        "    (df_elasticity_ppg_l2['price_elasticity'] < -1),\n",
        "    (df_elasticity_ppg_l2['price_elasticity'] > 0)\n",
        "    ]       \n",
        "df_elasticity_ppg_l2['elasticity_explanation'] = np.select(cust_ctg_ppg_elasticity_conditions_1, elasticity_explanation)\n",
        "df_elasticity_ppg_l2.to_csv(\"canada_cust_ctg_ppg_elasticity_details.csv\", index=False)\n",
        "\n",
        "df_ped_ppg = pd.DataFrame()\n",
        "for i in df_elasticity_ppg[['prod_category', 'ppg_id']].drop_duplicates().values.tolist():\n",
        "    test_df_ppg_ped = df_elasticity_ppg[(df_elasticity_ppg.prod_category == i[0]) & (df_elasticity_ppg.ppg_id == i[1])].reset_index().iloc[:,1:]\n",
        "    test_df_ppg_ped['ctg_ppg_ped_ranking'] = test_df_ppg_ped['price_elasticity'].rank(ascending = True).astype(int)\n",
        "    test_df_ppg_ped.sort_values('price_elasticity', ascending =False, inplace = True)\n",
        "    plt.figure(figsize = (20,10), dpi = 100)\n",
        "    plt.hlines(y = test_df_ppg_ped['ctg_ppg_ped_ranking'] , xmin = 0, xmax = test_df_ppg_ped['price_elasticity'], alpha = 0.5, linewidth = 3)\n",
        "    \n",
        "    \n",
        "    #Add elasticity labels\n",
        "    for x, y, tex in zip(test_df_ppg_ped['price_elasticity'], test_df_ppg_ped['ctg_ppg_ped_ranking'] , test_df_ppg_ped['price_elasticity']):\n",
        "        plt.text(x, y, round(tex, 2), horizontalalignment='right' if x < 0 else 'left', \n",
        "                 verticalalignment='center', fontdict={'color':'red' if x < 0 else 'green', 'size':15})\n",
        "    \n",
        "    # Axis and title\n",
        "    ylabel, xlabel = 'Ranking Number', 'Price Elasticity'\n",
        "    plt.gca().set(ylabel= ylabel, xlabel= xlabel)\n",
        "    plt.yticks(test_df_ppg_ped['ctg_ppg_ped_ranking'])\n",
        "    plt.title('price_elasticity' , fontdict={'size':15})\n",
        "    plt.grid(linestyle='--', alpha=0.5)\n",
        "    plt.show()\n",
        "    \n",
        "    #Adjust Ranking column and print dataframe\n",
        "    pd.set_option('display.width', 4000)\n",
        "    #cols = list(test_df_ppg_ped.columns)\n",
        "    #cols = [cols[-1]] + cols[:4]\n",
        "    cols = ['uch_level_g', 'prod_category', 'ppg_id', 'price_elasticity', 'ctg_ppg_ped_ranking', 'msg']\n",
        "    test_df_ppg_ped = test_df_ppg_ped[cols]\n",
        "    \n",
        "    test_df_ppg_ped = test_df_ppg_ped.iloc[:,:6]\n",
        "    test_df_ppg_ped.set_index('ctg_ppg_ped_ranking', inplace=True)\n",
        "    display(test_df_ppg_ped)\n",
        "    test_df_ppg_ped['ctg_ppg_ped_ranking'] = test_df_ppg_ped.index\n",
        "    df_ped_ppg = df_ped_ppg.append(test_df_ppg_ped)\n",
        "\n",
        "df_ped_ppg = df_ped_ppg.sort_values(by=['prod_category', 'ppg_id', 'price_elasticity'], ascending=[True, True, True])\n",
        "cust_ctg_ppg_elasticity_conditions = [\n",
        "    (df_ped_ppg['price_elasticity'] <= 0) & (df_ped_ppg['price_elasticity'] > -1),\n",
        "    (df_ped_ppg['price_elasticity'] == -1.000000000),\n",
        "    (df_ped_ppg['price_elasticity'] <= -1),\n",
        "    (df_ped_ppg['price_elasticity'] > 0)\n",
        "    ]   \n",
        "df_ped_ppg['elasticity_explanation'] = np.select(cust_ctg_ppg_elasticity_conditions, elasticity_explanation)\n",
        "\n",
        "#df_ped_ppg.to_csv(\"canada_cust_ctg_elasticity_summary.csv\", index=False)\n",
        "df_ped_ppg_l1 = pd.merge(df_ped_ppg, df_ctg_ppg, on = ['prod_category', 'ppg_id'], how='inner')\n",
        "df_ped_ppg_l2 = pd.merge(df_ped_ppg_l1, df_uch_level_g, on = ['uch_level_g'], how='inner')\n",
        "df_ped_ppg_l2.to_csv(\"canada_cust_ctg_ppg_elasticity_summary.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "INWaDk40o6gJ",
        "outputId": "bd57003f-b7db-4ca8-910a-85235ce55f69"
      },
      "source": [
        "df_elasticity_ppg_l2[(df_elasticity_ppg_l2.price_elasticity == 0) & (df_elasticity_ppg_l2.ppg_id=='025132003396Y46')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uch_level_g</th>\n",
              "      <th>prod_category</th>\n",
              "      <th>ppg_id</th>\n",
              "      <th>price_elasticity</th>\n",
              "      <th>t_score</th>\n",
              "      <th>coefficient_pvalue</th>\n",
              "      <th>slope</th>\n",
              "      <th>price_mean</th>\n",
              "      <th>quantity_mean</th>\n",
              "      <th>intercept</th>\n",
              "      <th>rsquared</th>\n",
              "      <th>msg</th>\n",
              "      <th>overall_ped_ranking</th>\n",
              "      <th>category_desc</th>\n",
              "      <th>ppg_desc</th>\n",
              "      <th>uch_level_e</th>\n",
              "      <th>uch_level_e_desc</th>\n",
              "      <th>uch_level_g_desc</th>\n",
              "      <th>elasticity_explanation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [uch_level_g, prod_category, ppg_id, price_elasticity, t_score, coefficient_pvalue, slope, price_mean, quantity_mean, intercept, rsquared, msg, overall_ped_ranking, category_desc, ppg_desc, uch_level_e, uch_level_e_desc, uch_level_g_desc, elasticity_explanation]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJuRxjVsOC2_"
      },
      "source": [
        "df_ped_ppg_l2[(df_ped_ppg_l2.price_elasticity == 0) & (df_ped_ppg_l2.ppg_id=='142047001404CG6')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7L4vOiyp9i1"
      },
      "source": [
        "df_elasticity_ppg_l2[(df_elasticity_ppg_l2.ppg_id=='018078502211VI2') & (df_elasticity_ppg_l2.uch_level_g=='CA4000428')][['elasticity_explanation', 'price_elasticity']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNMk9Wu3ANGL"
      },
      "source": [
        "df_ntl_ctg = pd.read_csv(\"result_national_elasticity_category.csv\")\n",
        "df_ntl_ctg.columns = [c.lower() for c in df_ntl_ctg.columns]\n",
        "df_ntl_ctg['total_sales_units_log'] = np.log(df_ntl_ctg.total_sales_units)\n",
        "df_ntl_ctg['avg_price_per_unit_to_consmer_log'] = np.log(df_ntl_ctg.avg_price_per_unit_to_consmer)\n",
        "orig_df_ntl_ctg = df_ntl_ctg.copy()\n",
        "df_ntl_ctg = df_ntl_ctg[df_ntl_ctg.prod_category.isin(br1_ctg)]\n",
        "df_ntl_ctg = df_ntl_ctg.sort_values(by=['fscl_wk_end_dt', 'prod_category'])\n",
        "\n",
        "unique_ctg_list = sorted(list(df_ntl_ctg['prod_category'].drop_duplicates()))\n",
        "\n",
        "ntl_ctg_results_values = {\n",
        "    \"prod_category\": [],\n",
        "    \"price_elasticity\": [],\n",
        "    \"price_mean\": [],\n",
        "    \"quantity_mean\": [],\n",
        "    \"intercept\": [],\n",
        "    \"t_score\":[],\n",
        "    \"slope\": [],\n",
        "    \"coefficient_pvalue\" : [],\n",
        "    \"rsquared\" : [],\n",
        "    \"msg\" : []\n",
        "}\n",
        "ntl_err_list = []\n",
        "for c in unique_ctg_list:\n",
        "    print(\"Processing prod category \" + str(c))\n",
        "    test_ntl_ctg_df = df[(df.prod_category == c)][['fscl_wk_end_dt', 'total_sales_units_log', 'avg_price_per_unit_to_consmer_log']]\n",
        "    test_ntl_ctg_df.set_index(\"fscl_wk_end_dt\", inplace=True)\n",
        "    try:\n",
        "        model_ntl_ctg = ols(\"total_sales_units_log ~ avg_price_per_unit_to_consmer_log\", data = test_ntl_ctg_df).fit()\n",
        "        print(model_ntl_ctg.summary())\n",
        "        \n",
        "        rsquared = model_ntl_ctg.rsquared\n",
        "        print(\"rsquared \" + str(rsquared))\n",
        "        coefficient_pvalue = model_ntl_ctg.f_pvalue\n",
        "        print(\"coefficient_pvalue \" + str(coefficient_pvalue))\n",
        "        intercept, slope = model_ntl_ctg.params\n",
        "        print(\"intercept \" + str(intercept))\n",
        "        print(\"slope \" + str(slope))\n",
        "        mean_price = np.mean(df_ntl_ctg[df_ntl_ctg.prod_category == c].avg_price_per_unit_to_consmer_log)\n",
        "        print(\"mean_price \" + str(mean_price))\n",
        "        mean_quantity = np.mean(df_ntl_ctg[df_ntl_ctg.prod_category == c].total_sales_units_log)\n",
        "        print(\"mean_quantity \" + str(mean_quantity))\n",
        "        tintercept, t_score = model_ntl_ctg.tvalues\n",
        "        print(\"tintercept \" + str(tintercept))\n",
        "        print(\"t_score \" + str(t_score))\n",
        "        \n",
        "        price_elasticity = (slope)\n",
        "        \n",
        "        #Append results into dictionary for dataframe\n",
        "        ntl_ctg_results_values[\"prod_category\"].append(c)\n",
        "        ntl_ctg_results_values[\"price_elasticity\"].append(price_elasticity)\n",
        "        ntl_ctg_results_values[\"price_mean\"].append(mean_price)\n",
        "        ntl_ctg_results_values[\"quantity_mean\"].append(mean_quantity)\n",
        "        ntl_ctg_results_values[\"intercept\"].append(intercept)\n",
        "        ntl_ctg_results_values['t_score'].append(t_score)\n",
        "        ntl_ctg_results_values[\"slope\"].append(slope)\n",
        "        ntl_ctg_results_values[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
        "        ntl_ctg_results_values['rsquared'].append(rsquared)\n",
        "        if coefficient_pvalue < 0.05:\n",
        "            ntl_ctg_results_values[\"msg\"].append(\"coefficient_pvalue < 0.05, statistically significant results\")\n",
        "        else:\n",
        "            ntl_ctg_results_values[\"msg\"].append(\"coefficient_pvalue >= 0.05, statistically insignificant results\")\n",
        "        print(\"Model results printed\")\n",
        "        print(\"*******************************************************************\")\n",
        "    except:\n",
        "        print(\"Error occurred\")\n",
        "        ntl_err_list.append(c)\n",
        "\n",
        "final_df_ntl_ctg = pd.DataFrame.from_dict(ntl_ctg_results_values)\n",
        "df_ntl_ctg_elasticity = final_df_ntl_ctg[['prod_category','price_elasticity','t_score','coefficient_pvalue','slope','price_mean','quantity_mean','intercept','rsquared','msg']]\n",
        "pe_plot = divergent_plot(df_ntl_ctg_elasticity, 'price_elasticity', 'overall_ped_ranking', 'price_elasticity')\n",
        "\n",
        "df_ntl_ctg_elasticity_l1 = pd.merge(df_ntl_ctg_elasticity, df_ctg, on = ['prod_category'], how='inner')\n",
        "ntl_ctg_elasticity_conditions = [\n",
        "    (df_ntl_ctg_elasticity_l1['price_elasticity'] <= 0) & (df_ntl_ctg_elasticity_l1['price_elasticity'] > -1),\n",
        "    (df_ntl_ctg_elasticity_l1['price_elasticity'] == -1.000000000),\n",
        "    (df_ntl_ctg_elasticity_l1['price_elasticity'] < -1),\n",
        "    (df_ntl_ctg_elasticity_l1['price_elasticity'] > 0)\n",
        "    ]  \n",
        "df_ntl_ctg_elasticity_l1['elasticity_explanation'] = np.select(ntl_ctg_elasticity_conditions, elasticity_explanation)\n",
        "df_ntl_ctg_elasticity_l1.to_csv(\"canada_national_category_elasticity_details.csv\", index=False)\n",
        "df_ntl_ctg_elasticity_l1[['prod_category', 'category_desc', 'price_elasticity', 'overall_ped_ranking', 'msg', 'elasticity_explanation']].sort_values(by = ['price_elasticity']).to_csv(\"canada_national_category_elasticity_summary.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do3fE2MrXZ9Q"
      },
      "source": [
        "orig_df_ntl_ctg_pivot = df_ntl_ctg.pivot(index = 'fscl_wk_end_dt', columns = ['prod_category'], values = 'total_sales_units')\n",
        "formatted_column_name_list = []\n",
        "for c in orig_df_ntl_ctg_pivot.columns:\n",
        "    formatted_column_name_list.append('ctg_' + str(c))\n",
        "orig_df_ntl_ctg_pivot.columns = formatted_column_name_list\n",
        "orig_df_ntl_ctg_pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhWQC-VQneIj"
      },
      "source": [
        "for c in df_ntl_ctg.prod_category.values.tolist():\n",
        "    print(\"Processing category \" + str(c))\n",
        "    plt.show( block=False )\n",
        "    temp_ntl_df = df_ntl_ctg[df_ntl_ctg.prod_category ==  c]\n",
        "    temp_ntl_df.set_index('fscl_wk_end_dt', inplace = True)\n",
        "    temp_ntl_df[temp_ntl_df.prod_category ==  c].total_sales_units.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjLzFruUiGTL"
      },
      "source": [
        "orig_df_ntl_ctg_pivot.plot(figsize=(20,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7jGc5FaoHC"
      },
      "source": [
        "df_ntl_cust = df.groupby(['uch_level_g', 'fscl_wk_end_dt']).agg({\"total_sales_units_log\" : \"sum\", \"avg_price_per_unit_to_consmer_log\" : \"sum\"}).reset_index()\n",
        "df_ntl_cust = df_ntl_cust.sort_values(by=['fscl_wk_end_dt', 'uch_level_g'])\n",
        "\n",
        "unique_ctg_list = sorted(list(df_ntl_cust['uch_level_g'].drop_duplicates()))\n",
        "\n",
        "ntl_cust_results_values = {\n",
        "    \"uch_level_g\": [],\n",
        "    \"price_elasticity\": [],\n",
        "    \"price_mean\": [],\n",
        "    \"quantity_mean\": [],\n",
        "    \"intercept\": [],\n",
        "    \"t_score\":[],\n",
        "    \"slope\": [],\n",
        "    \"coefficient_pvalue\" : [],\n",
        "    \"rsquared\" : [],\n",
        "    \"msg\" : []\n",
        "}\n",
        "ntl_err_list = []\n",
        "for c in unique_ctg_list:\n",
        "    print(\"Processing prod category \" + str(c))\n",
        "    test_ntl_ctg_df = df[(df.uch_level_g == c)][['fscl_wk_end_dt', 'total_sales_units_log', 'avg_price_per_unit_to_consmer_log']]\n",
        "    test_ntl_ctg_df.set_index(\"fscl_wk_end_dt\", inplace=True)\n",
        "    try:\n",
        "        model_ntl_ctg = ols(\"total_sales_units_log ~ avg_price_per_unit_to_consmer_log\", data = test_ntl_ctg_df).fit()\n",
        "        print(model_ntl_ctg.summary())\n",
        "        \n",
        "        rsquared = model_ntl_ctg.rsquared\n",
        "        print(\"rsquared \" + str(rsquared))\n",
        "        coefficient_pvalue = model_ntl_ctg.f_pvalue\n",
        "        print(\"coefficient_pvalue \" + str(coefficient_pvalue))\n",
        "        intercept, slope = model_ntl_ctg.params\n",
        "        print(\"intercept \" + str(intercept))\n",
        "        print(\"slope \" + str(slope))\n",
        "        mean_price = np.mean(df_ntl_cust[df_ntl_cust.uch_level_g == c].avg_price_per_unit_to_consmer_log)\n",
        "        print(\"mean_price \" + str(mean_price))\n",
        "        mean_quantity = np.mean(df_ntl_cust[df_ntl_cust.uch_level_g == c].total_sales_units_log)\n",
        "        print(\"mean_quantity \" + str(mean_quantity))\n",
        "        tintercept, t_score = model_ntl_ctg.tvalues\n",
        "        print(\"tintercept \" + str(tintercept))\n",
        "        print(\"t_score \" + str(t_score))\n",
        "        \n",
        "        price_elasticity = (slope)\n",
        "        \n",
        "        #Append results into dictionary for dataframe\n",
        "        ntl_cust_results_values[\"uch_level_g\"].append(c)\n",
        "        ntl_cust_results_values[\"price_elasticity\"].append(price_elasticity)\n",
        "        ntl_cust_results_values[\"price_mean\"].append(mean_price)\n",
        "        ntl_cust_results_values[\"quantity_mean\"].append(mean_quantity)\n",
        "        ntl_cust_results_values[\"intercept\"].append(intercept)\n",
        "        ntl_cust_results_values['t_score'].append(t_score)\n",
        "        ntl_cust_results_values[\"slope\"].append(slope)\n",
        "        ntl_cust_results_values[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
        "        ntl_cust_results_values['rsquared'].append(rsquared)\n",
        "        if coefficient_pvalue < 0.05:\n",
        "            ntl_cust_results_values[\"msg\"].append(\"coefficient_pvalue < 0.05, statistically significant results\")\n",
        "        else:\n",
        "            ntl_cust_results_values[\"msg\"].append(\"coefficient_pvalue >= 0.05, statistically insignificant results\")\n",
        "        print(\"Model results printed\")\n",
        "        print(\"*******************************************************************\")\n",
        "    except:\n",
        "        print(\"Error occurred\")\n",
        "        ntl_err_list.append(c)\n",
        "\n",
        "final_df_ntl_cust = pd.DataFrame.from_dict(ntl_cust_results_values)\n",
        "df_ntl_cust_elasticity = final_df_ntl_cust[['uch_level_g','price_elasticity','t_score','coefficient_pvalue','slope','price_mean','quantity_mean','intercept','rsquared','msg']]\n",
        "pe_plot = divergent_plot(df_ntl_cust_elasticity, 'price_elasticity', 'overall_ped_ranking', 'price_elasticity')\n",
        "\n",
        "df_ntl_cust_elasticity_l1 = pd.merge(df_ntl_cust_elasticity, df_uch_level_g, on = ['uch_level_g'], how='inner')\n",
        "ntl_cust_elasticity_conditions = [\n",
        "    (df_ntl_cust_elasticity_l1['price_elasticity'] <= 0) & (df_ntl_cust_elasticity_l1['price_elasticity'] > -1),\n",
        "    (df_ntl_cust_elasticity_l1['price_elasticity'] == -1.000000000),\n",
        "    (df_ntl_cust_elasticity_l1['price_elasticity'] < -1),\n",
        "    (df_ntl_cust_elasticity_l1['price_elasticity'] > 0)\n",
        "    ]   \n",
        "df_ntl_cust_elasticity_l1['elasticity_explanation'] = np.select(ntl_cust_elasticity_conditions, elasticity_explanation)\n",
        "df_ntl_cust_elasticity_l1.to_csv(\"canada_national_customer_elasticity_details.csv\", index=False)\n",
        "df_ntl_cust_elasticity_l1[['uch_level_e', 'uch_level_e_desc','uch_level_g', 'uch_level_g_desc', 'price_elasticity', 'overall_ped_ranking', 'msg', 'elasticity_explanation']].sort_values(by = ['price_elasticity']).to_csv(\"canada_national_customer_elasticity_summary.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fim7Ap_05Uwj"
      },
      "source": [
        "df_ntl_ppg = df_ppg.groupby(['ppg_id', 'fscl_wk_end_dt']).agg({\"total_sales_units_log\" : \"sum\", \"avg_price_per_unit_to_consmer_log\" : \"sum\"}).reset_index()\n",
        "df_ntl_ppg = df_ntl_ppg.sort_values(by=['fscl_wk_end_dt', 'ppg_id'])\n",
        "\n",
        "unique_ppg_list = sorted(list(df_ntl_ppg['ppg_id'].drop_duplicates()))\n",
        "\n",
        "ntl_ppg_results_values = {\n",
        "    \"ppg_id\": [],\n",
        "    \"price_elasticity\": [],\n",
        "    \"price_mean\": [],\n",
        "    \"quantity_mean\": [],\n",
        "    \"intercept\": [],\n",
        "    \"t_score\":[],\n",
        "    \"slope\": [],\n",
        "    \"coefficient_pvalue\" : [],\n",
        "    \"rsquared\" : [],\n",
        "    \"msg\" : []\n",
        "}\n",
        "ntl_err_list = []\n",
        "for c in unique_ppg_list:\n",
        "    print(\"Processing ppg \" + c)\n",
        "    test_ntl_ppg_df = df[(df.uch_level_g == c)][['fscl_wk_end_dt', 'total_sales_units_log', 'avg_price_per_unit_to_consmer_log']]\n",
        "    test_ntl_ppg_df.set_index(\"fscl_wk_end_dt\", inplace=True)\n",
        "    try:\n",
        "        model_ntl_ppg = ols(\"total_sales_units_log ~ avg_price_per_unit_to_consmer_log\", data = test_ntl_ppg_df).fit()\n",
        "        print(model_ntl_ppg.summary())\n",
        "        \n",
        "        rsquared = model_ntl_ppg.rsquared\n",
        "        print(\"rsquared \" + str(rsquared))\n",
        "        coefficient_pvalue = model_ntl_ppg.f_pvalue\n",
        "        print(\"coefficient_pvalue \" + str(coefficient_pvalue))\n",
        "        intercept, slope = model_ntl_ppg.params\n",
        "        print(\"intercept \" + str(intercept))\n",
        "        print(\"slope \" + str(slope))\n",
        "        mean_price = np.mean(df_ntl_ppg[df_ntl_cust.uch_level_g == c].avg_price_per_unit_to_consmer_log)\n",
        "        print(\"mean_price \" + str(mean_price))\n",
        "        mean_quantity = np.mean(df_ntl_ppg[df_ntl_cust.uch_level_g == c].total_sales_units_log)\n",
        "        print(\"mean_quantity \" + str(mean_quantity))\n",
        "        tintercept, t_score = model_ntl_ppg.tvalues\n",
        "        print(\"tintercept \" + str(tintercept))\n",
        "        print(\"t_score \" + str(t_score))\n",
        "        \n",
        "        price_elasticity = (slope)\n",
        "        \n",
        "        #Append results into dictionary for dataframe\n",
        "        ntl_ppg_results_values[\"ppg_id\"].append(c)\n",
        "        ntl_ppg_results_values[\"price_elasticity\"].append(price_elasticity)\n",
        "        ntl_ppg_results_values[\"price_mean\"].append(mean_price)\n",
        "        ntl_ppg_results_values[\"quantity_mean\"].append(mean_quantity)\n",
        "        ntl_ppg_results_values[\"intercept\"].append(intercept)\n",
        "        ntl_ppg_results_values['t_score'].append(t_score)\n",
        "        ntl_ppg_results_values[\"slope\"].append(slope)\n",
        "        ntl_ppg_results_values[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
        "        ntl_ppg_results_values['rsquared'].append(rsquared)\n",
        "        if coefficient_pvalue < 0.05:\n",
        "            ntl_ppg_results_values[\"msg\"].append(\"coefficient_pvalue < 0.05, statistically significant results\")\n",
        "        else:\n",
        "            ntl_ppg_results_values[\"msg\"].append(\"coefficient_pvalue >= 0.05, statistically insignificant results\")\n",
        "        print(\"Model results printed\")\n",
        "        print(\"*******************************************************************\")\n",
        "    except:\n",
        "        print(\"Error occurred\")\n",
        "        ntl_err_list.append(c)\n",
        "\n",
        "final_df_ntl_ppg = pd.DataFrame.from_dict(ntl_ppg_results_values)\n",
        "df_ntl_ppg_elasticity = final_df_ntl_ppg[['ppg_id','price_elasticity','t_score','coefficient_pvalue','slope','price_mean','quantity_mean','intercept','rsquared','msg']]\n",
        "pe_plot = divergent_plot(df_ntl_ppg_elasticity, 'price_elasticity', 'overall_ped_ranking', 'price_elasticity')\n",
        "\n",
        "df_ntl_ppg_elasticity_l1 = pd.merge(df_ntl_ppg_elasticity, df_ppg_list, on = ['ppg_id'], how='inner')\n",
        "ntl_ppg_elasticity_conditions = [\n",
        "    (df_ntl_ppg_elasticity_l1['price_elasticity'] <= 0) & (df_ntl_ppg_elasticity_l1['price_elasticity'] > -1),\n",
        "    (df_ntl_ppg_elasticity_l1['price_elasticity'] == -1.000000000),\n",
        "    (df_ntl_ppg_elasticity_l1['price_elasticity'] < -1),\n",
        "    (df_ntl_ppg_elasticity_l1['price_elasticity'] > 0)\n",
        "    ]   \n",
        "df_ntl_ppg_elasticity_l1['elasticity_explanation'] = np.select(ntl_ppg_elasticity_conditions, elasticity_explanation)\n",
        "df_ntl_ppg_elasticity_l1.to_csv(\"canada_national_ppg_elasticity_details.csv\", index=False)\n",
        "df_ntl_ppg_elasticity_l1[['ppg_id', 'ppg_desc','price_elasticity', 'overall_ped_ranking', 'msg', 'elasticity_explanation']].sort_values(by = ['price_elasticity']).to_csv(\"canada_national_customer_elasticity_summary.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE800OgX9Wlr"
      },
      "source": [
        "df_ntl_ppg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIoqNjDy7kYW"
      },
      "source": [
        "df_ppg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxwMbbLAaoKQ"
      },
      "source": [
        "#!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "gNZ0P3p5aoNb",
        "outputId": "928e88d1-c207-4705-aa6a-2f28f905efd7"
      },
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas_profiling import ProfileReport\n",
        "df = pd.read_csv(\"result_elasticity_data_ctg.csv\")\n",
        "df.columns = [c.lower() for c in df.columns]\n",
        "df['total_sales_units_log'] = np.log(df.total_sales_units)\n",
        "df['avg_price_per_unit_to_consmer_log'] = np.log(df.avg_price_per_unit_to_consmer)\n",
        "orig_df = df.copy()\n",
        "#df = df[df.prod_category.isin(br1_ctg)]\n",
        "df = df.sort_values(by=['fscl_wk_end_dt', 'prod_category', 'uch_level_g'])\n",
        "\n",
        "profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
        "profile\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport pandas as pd\\nimport numpy as np\\nfrom pandas_profiling import ProfileReport\\ndf = pd.read_csv(\"result_elasticity_data_ctg.csv\")\\ndf.columns = [c.lower() for c in df.columns]\\ndf[\\'total_sales_units_log\\'] = np.log(df.total_sales_units)\\ndf[\\'avg_price_per_unit_to_consmer_log\\'] = np.log(df.avg_price_per_unit_to_consmer)\\norig_df = df.copy()\\n#df = df[df.prod_category.isin(br1_ctg)]\\ndf = df.sort_values(by=[\\'fscl_wk_end_dt\\', \\'prod_category\\', \\'uch_level_g\\'])\\n\\nprofile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erp6J811aoQa",
        "outputId": "2e4aebec-d71c-48dc-c511-8b7f31828ecf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/basic.py:300: UserWarning: %profile is now deprecated. Please use get_ipython().profile instead.\n",
            "  warn(\"%profile is now deprecated. Please use get_ipython().profile instead.\")\n"
          ]
        }
      ]
    }
  ]
}